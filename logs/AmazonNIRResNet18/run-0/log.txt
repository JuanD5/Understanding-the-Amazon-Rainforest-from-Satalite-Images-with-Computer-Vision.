Namespace(batch_size=8, cuda=True, epochs=20, gamma=2, gpu='1', input_size=256, log_interval=10, lr=0.001, model='AmazonNIRResNet18', momentum=0.5, nir_channel='NIR-R-G', no_cuda=False, patience=20, save='model.pt', seed=1, test_batch_size=128, v=False)
AmazonNIRResNet18(
  (pretrained_model): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Sequential(
      (0): Linear(in_features=512, out_features=17, bias=True)
    )
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=17, bias=True)
  )
)
Epoch: 0	 train loss: 0.169, train acc: 0.936	
                val loss: 0.127, val acc: 0.952	 fscore: 0.884	
                time: 806.3s
Epoch: 1	 train loss: 0.137, train acc: 0.949	
                val loss: 0.115, val acc: 0.957	 fscore: 0.897	
                time: 804.3s
Epoch: 2	 train loss: 0.127, train acc: 0.953	
                val loss: 0.110, val acc: 0.959	 fscore: 0.901	
                time: 819.2s
Epoch: 3	 train loss: 0.121, train acc: 0.955	
                val loss: 0.103, val acc: 0.962	 fscore: 0.908	
                time: 820.9s
Epoch: 4	 train loss: 0.117, train acc: 0.957	
                val loss: 0.098, val acc: 0.963	 fscore: 0.914	
                time: 812.9s
Epoch: 5	 train loss: 0.112, train acc: 0.959	
                val loss: 0.095, val acc: 0.964	 fscore: 0.917	
                time: 810.1s
Epoch: 6	 train loss: 0.108, train acc: 0.960	
                val loss: 0.091, val acc: 0.966	 fscore: 0.920	
                time: 805.9s
Epoch: 7	 train loss: 0.104, train acc: 0.961	
                val loss: 0.087, val acc: 0.967	 fscore: 0.923	
                time: 805.0s
Epoch: 8	 train loss: 0.100, train acc: 0.963	
                val loss: 0.081, val acc: 0.970	 fscore: 0.929	
                time: 817.3s
Epoch: 9	 train loss: 0.095, train acc: 0.965	
                val loss: 0.076, val acc: 0.971	 fscore: 0.933	
                time: 810.5s
Epoch: 10	 train loss: 0.090, train acc: 0.967	
                val loss: 0.069, val acc: 0.975	 fscore: 0.941	
                time: 817.1s
Epoch: 11	 train loss: 0.086, train acc: 0.969	
                val loss: 0.063, val acc: 0.977	 fscore: 0.946	
                time: 819.1s
Epoch: 12	 train loss: 0.081, train acc: 0.971	
                val loss: 0.059, val acc: 0.979	 fscore: 0.952	
                time: 806.5s
Epoch: 13	 train loss: 0.074, train acc: 0.973	
                val loss: 0.053, val acc: 0.981	 fscore: 0.957	
                time: 812.9s
Epoch: 14	 train loss: 0.069, train acc: 0.975	
                val loss: 0.045, val acc: 0.985	 fscore: 0.965	
                time: 807.6s
Epoch: 15	 train loss: 0.064, train acc: 0.977	
                val loss: 0.043, val acc: 0.986	 fscore: 0.969	
                time: 811.6s
Epoch: 16	 train loss: 0.060, train acc: 0.979	
                val loss: 0.037, val acc: 0.989	 fscore: 0.975	
                time: 819.0s
Epoch: 17	 train loss: 0.054, train acc: 0.981	
                val loss: 0.032, val acc: 0.991	 fscore: 0.979	
                time: 816.4s
Epoch: 18	 train loss: 0.050, train acc: 0.983	
                val loss: 0.030, val acc: 0.991	 fscore: 0.980	
                time: 816.4s
Epoch: 19	 train loss: 0.045, train acc: 0.985	
                val loss: 0.026, val acc: 0.992	 fscore: 0.984	
                time: 890.8s
