Namespace(batch_size=8, cuda=True, epochs=20, gamma=2, gpu='1', input_size=256, log_interval=10, lr=0.001, model='AmazonNIRResNet18', momentum=0.5, nir_channel='NIR-R-B', no_cuda=False, patience=20, save='model.pt', seed=1, test_batch_size=128, v=False)
AmazonNIRResNet18(
  (pretrained_model): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Sequential(
      (0): Linear(in_features=512, out_features=17, bias=True)
    )
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=17, bias=True)
  )
)
Epoch: 0	 train loss: 0.168, train acc: 0.936	
                val loss: 0.126, val acc: 0.953	 fscore: 0.884	
                time: 927.2s
Epoch: 1	 train loss: 0.136, train acc: 0.950	
                val loss: 0.114, val acc: 0.957	 fscore: 0.898	
                time: 931.8s
Epoch: 2	 train loss: 0.127, train acc: 0.953	
                val loss: 0.109, val acc: 0.959	 fscore: 0.901	
                time: 937.4s
Epoch: 3	 train loss: 0.121, train acc: 0.956	
                val loss: 0.103, val acc: 0.962	 fscore: 0.909	
                time: 936.3s
Epoch: 4	 train loss: 0.117, train acc: 0.957	
                val loss: 0.098, val acc: 0.964	 fscore: 0.914	
                time: 932.4s
Epoch: 5	 train loss: 0.112, train acc: 0.959	
                val loss: 0.095, val acc: 0.965	 fscore: 0.917	
                time: 930.1s
Epoch: 6	 train loss: 0.107, train acc: 0.960	
                val loss: 0.089, val acc: 0.967	 fscore: 0.921	
                time: 931.4s
Epoch: 7	 train loss: 0.104, train acc: 0.962	
                val loss: 0.085, val acc: 0.968	 fscore: 0.925	
                time: 930.0s
Epoch: 8	 train loss: 0.100, train acc: 0.963	
                val loss: 0.079, val acc: 0.971	 fscore: 0.930	
                time: 926.7s
Epoch: 9	 train loss: 0.094, train acc: 0.965	
                val loss: 0.075, val acc: 0.971	 fscore: 0.934	
                time: 930.9s
Epoch: 10	 train loss: 0.089, train acc: 0.967	
                val loss: 0.069, val acc: 0.975	 fscore: 0.942	
                time: 927.2s
Epoch: 11	 train loss: 0.085, train acc: 0.969	
                val loss: 0.064, val acc: 0.976	 fscore: 0.945	
                time: 932.1s
Epoch: 12	 train loss: 0.080, train acc: 0.971	
                val loss: 0.057, val acc: 0.980	 fscore: 0.955	
                time: 931.5s
Epoch: 13	 train loss: 0.074, train acc: 0.974	
                val loss: 0.051, val acc: 0.983	 fscore: 0.961	
                time: 937.2s
Epoch: 14	 train loss: 0.068, train acc: 0.976	
                val loss: 0.044, val acc: 0.985	 fscore: 0.966	
                time: 936.9s
Epoch: 15	 train loss: 0.063, train acc: 0.978	
                val loss: 0.041, val acc: 0.987	 fscore: 0.971	
                time: 932.7s
Epoch: 16	 train loss: 0.058, train acc: 0.980	
                val loss: 0.036, val acc: 0.989	 fscore: 0.976	
                time: 931.7s
Epoch: 17	 train loss: 0.053, train acc: 0.982	
                val loss: 0.031, val acc: 0.991	 fscore: 0.980	
                time: 937.4s
Epoch: 18	 train loss: 0.048, train acc: 0.984	
                val loss: 0.027, val acc: 0.992	 fscore: 0.982	
                time: 935.8s
Epoch: 19	 train loss: 0.044, train acc: 0.985	
                val loss: 0.023, val acc: 0.994	 fscore: 0.986	
                time: 937.9s
