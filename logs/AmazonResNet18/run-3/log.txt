Namespace(batch_size=4, cuda=True, epochs=20, gamma=2, gpu='1', input_size=256, log_interval=10, lr=0.001, model='AmazonResNet18', momentum=0.5, nir_channel='normal', no_cuda=False, patience=20, resume='', save='model.pt', seed=1, start_epoch=0, test_batch_size=128, v=False)
AmazonResNet18(
  (pretrained_model): ResNet(
    (conv1): Conv2d(4, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Sequential(
      (0): Linear(in_features=512, out_features=17, bias=True)
    )
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=17, bias=True)
  )
)
Epoch: 0	 train loss: 0.205, train acc: 0.921	
                val loss: 0.189, val acc: 0.929	 fscore: 0.814	
                time: 2099.2s
Epoch: 1	 train loss: 0.180, train acc: 0.932	
                val loss: 0.171, val acc: 0.937	 fscore: 0.839	
                time: 2086.3s
Epoch: 2	 train loss: 0.172, train acc: 0.936	
                val loss: 0.165, val acc: 0.941	 fscore: 0.846	
                time: 2106.4s
Epoch: 3	 train loss: 0.165, train acc: 0.939	
                val loss: 0.170, val acc: 0.940	 fscore: 0.847	
                time: 2076.1s
Epoch: 4	 train loss: 0.159, train acc: 0.941	
                val loss: 0.174, val acc: 0.940	 fscore: 0.845	
                time: 2072.2s
Epoch: 5	 train loss: 0.155, train acc: 0.943	
                val loss: 0.158, val acc: 0.945	 fscore: 0.859	
                time: 2081.2s
Epoch: 6	 train loss: 0.150, train acc: 0.945	
                val loss: 0.159, val acc: 0.946	 fscore: 0.863	
                time: 2077.3s
Epoch: 7	 train loss: 0.146, train acc: 0.946	
                val loss: 0.165, val acc: 0.943	 fscore: 0.860	
                time: 2084.2s
Epoch: 8	 train loss: 0.142, train acc: 0.948	
                val loss: 0.179, val acc: 0.942	 fscore: 0.860	
                time: 2102.7s
Epoch: 9	 train loss: 0.138, train acc: 0.949	
                val loss: 0.152, val acc: 0.948	 fscore: 0.875	
                time: 2852.2s
Epoch: 10	 train loss: 0.134, train acc: 0.950	
                val loss: 0.148, val acc: 0.950	 fscore: 0.876	
                time: 2339.4s
Epoch: 11	 train loss: 0.130, train acc: 0.952	
                val loss: 0.149, val acc: 0.949	 fscore: 0.874	
                time: 2433.0s
Epoch: 12	 train loss: 0.126, train acc: 0.953	
                val loss: 0.142, val acc: 0.954	 fscore: 0.887	
                time: 2112.5s
Epoch: 13	 train loss: 0.122, train acc: 0.955	
                val loss: 0.136, val acc: 0.956	 fscore: 0.890	
                time: 2077.9s
Epoch: 14	 train loss: 0.117, train acc: 0.957	
                val loss: 0.133, val acc: 0.957	 fscore: 0.891	
                time: 2074.0s
Epoch: 15	 train loss: 0.112, train acc: 0.959	
                val loss: 0.115, val acc: 0.962	 fscore: 0.907	
                time: 2079.2s
Epoch: 16	 train loss: 0.106, train acc: 0.961	
                val loss: 0.117, val acc: 0.960	 fscore: 0.898	
                time: 2078.2s
Epoch: 17	 train loss: 0.100, train acc: 0.963	
                val loss: 0.099, val acc: 0.967	 fscore: 0.918	
                time: 2077.0s
Epoch: 18	 train loss: 0.094, train acc: 0.965	
                val loss: 0.112, val acc: 0.968	 fscore: 0.920	
                time: 2074.0s
Epoch: 19	 train loss: 0.089, train acc: 0.968	
                val loss: 0.099, val acc: 0.971	 fscore: 0.922	
                time: 2075.8s
